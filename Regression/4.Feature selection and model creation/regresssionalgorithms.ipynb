{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1298463e-e9cd-42a7-ad4f-65be06500f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25bcd2c-fe1c-45fd-b29d-df12200d1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"healthcaredata_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17721ac9-8da4-406f-b977-24a77ba48f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b571542-48bb-4af1-843f-58adf1d4263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15640481-193b-4509-ada4-38800fbe8cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "bmi                 0\n",
       "children            0\n",
       "charges             0\n",
       "sex_male            0\n",
       "smoker_yes          0\n",
       "region_northwest    0\n",
       "region_southeast    0\n",
       "region_southwest    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647a87e8-ffb5-41dc-8373-437a11569780",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataset.drop('charges', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3293dcc3-c8bb-410c-80ad-8f3371d98fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = dataset[['charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1aadaa-8797-4a42-9811-736696755c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d2b36-016d-4028-83f0-a5c5875ddfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb739e81-f599-4e15-b019-ce867e341d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsril\\anaconda3\\envs\\numpy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jsril\\anaconda3\\envs\\numpy_env\\lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jsril\\anaconda3\\envs\\numpy_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\jsril\\anaconda3\\envs\\numpy_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 317\n",
      "[LightGBM] [Info] Number of data points in the train set: 935, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 13063.437459\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "def split_data(independent,dependent):\n",
    "    X_train,X_test,y_train, y_test = train_test_split(independent, dependent, test_size=0.3, random_state=32)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def linear_regression(X_train,X_test,y_train):\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    \n",
    "def Support_Vectormachine(X_train,X_test,y_train):\n",
    "    regressor = SVR(kernel='sigmoid', C=1000, gamma='auto') \n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "\n",
    "def random_forest(X_train,X_test,y_train):\n",
    "    regressor = RandomForestRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    # r2scores = r2_scorecalc(regressor, X_test, y_test)\n",
    "    # return r2scores\n",
    "\n",
    "def decision_trees(X_train,X_test,y_train):\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    \n",
    "def ridge(X_train,X_test,y_train):\n",
    "    regressor = Ridge()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    \n",
    "def lasso(X_train,X_test,y_train):\n",
    "    regressor = Lasso()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "\n",
    "def Xg_boost(X_train,X_test,y_train):\n",
    "    import xgboost as xgb\n",
    "    regressor = xgb.XGBRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "\n",
    "def gradient_boost(X_train,X_test,y_train):\n",
    "    regressor = GradientBoostingRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    \n",
    "def ada_boost(X_train,X_test,y_train):\n",
    "    regressor = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "    \n",
    "def lightgbm_boost(X_train,X_test,y_train):\n",
    "    import lightgbm as lgb\n",
    "    regressor = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    r2scores,meansqr,meanabs = r2_scorecalc(regressor, X_test, y_test)\n",
    "    return r2scores,meansqr,meanabs\n",
    "\n",
    "#calculating r2 score\n",
    "def r2_scorecalc(regressor, X_test, y_test):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    r2 =r2_score(y_test,y_pred)\n",
    "    sqr = mean_squared_error(y_test,y_pred)\n",
    "    meanabsolute=mean_absolute_error(y_test,y_pred)\n",
    "    return r2,sqr,meanabsolute\n",
    "    \n",
    "r2_scores = []\n",
    "meansq_score=[]\n",
    "mean_absscore=[]\n",
    "\n",
    "X_train,X_test,y_train, y_test = split_data(independent, dependent)\n",
    "score1,score2,score3 = linear_regression(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = Support_Vectormachine(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = random_forest(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = decision_trees(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = ridge(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = lasso(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = Xg_boost(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = gradient_boost(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = ada_boost(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n",
    "score1,score2,score3 = lightgbm_boost(X_train,X_test,y_train)\n",
    "r2_scores.append(score1)\n",
    "meansq_score.append(score2)\n",
    "mean_absscore.append(score3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f26ed-ff4d-4ce2-8dcd-84a832e9aa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59a6413-503d-4396-9327-05876544b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MeanSquaredError</th>\n",
       "      <th>MeanAbsoluteError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.742059</td>\n",
       "      <td>3.863930e+07</td>\n",
       "      <td>4375.440921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>-0.143712</td>\n",
       "      <td>1.713268e+08</td>\n",
       "      <td>8666.761701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.831677</td>\n",
       "      <td>2.521467e+07</td>\n",
       "      <td>2722.161888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.695701</td>\n",
       "      <td>4.558370e+07</td>\n",
       "      <td>3329.612259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.742371</td>\n",
       "      <td>3.859254e+07</td>\n",
       "      <td>4385.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.742062</td>\n",
       "      <td>3.863887e+07</td>\n",
       "      <td>4375.671456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xg_boost</th>\n",
       "      <td>0.802186</td>\n",
       "      <td>2.963226e+07</td>\n",
       "      <td>3193.907959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boost</th>\n",
       "      <td>0.846539</td>\n",
       "      <td>2.298829e+07</td>\n",
       "      <td>2533.643695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada_boost</th>\n",
       "      <td>0.823975</td>\n",
       "      <td>2.636835e+07</td>\n",
       "      <td>3632.581991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.849127</td>\n",
       "      <td>2.260055e+07</td>\n",
       "      <td>2502.636984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R2Score  MeanSquaredError  MeanAbsoluteError\n",
       "LinearRegression  0.742059      3.863930e+07        4375.440921\n",
       "SVM              -0.143712      1.713268e+08        8666.761701\n",
       "RF                0.831677      2.521467e+07        2722.161888\n",
       "DT                0.695701      4.558370e+07        3329.612259\n",
       "Ridge             0.742371      3.859254e+07        4385.502600\n",
       "Lasso             0.742062      3.863887e+07        4375.671456\n",
       "Xg_boost          0.802186      2.963226e+07        3193.907959\n",
       "gradient_boost    0.846539      2.298829e+07        2533.643695\n",
       "ada_boost         0.823975      2.636835e+07        3632.581991\n",
       "LightGBM          0.849127      2.260055e+07        2502.636984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_report = pd.DataFrame({\n",
    "    'R2Score': r2_scores,\n",
    "    'MeanSquaredError':meansq_score,\n",
    "    'MeanAbsoluteError':mean_absscore\n",
    "},index=['LinearRegression','SVM','RF','DT','Ridge','Lasso','Xg_boost','gradient_boost','ada_boost','LightGBM'])\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a33690-1520-4496-9dc3-86132b289689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lightgbm xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad07ef9-565e-48cd-b3d6-1343afd2a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "Light GBM and gradient boosting has r2 score of 84%. Random Forest has 83%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (numpy_env)",
   "language": "python",
   "name": "numpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
